{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a706ac-534e-4a85-8cb4-ac55ef56a6f9",
   "metadata": {},
   "source": [
    "The transription is done using google speech recognition API. The transcription was not perfect. Some of the repeated errors during transcription is corrected using seperate functions. The quantity of each food item is found using dependency parser. Some of the correct transcription also gave wrong output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e3127f-8d28-4836-844c-58e613c8cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilsh\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "from word2number import w2n\n",
    "import re\n",
    "\n",
    "# Download the spaCy model\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb5ca42-3847-4b9d-8f8c-39ab6b63c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio text is I need to Pizza three burgers and one Sathya\n",
      "corrected text i want two number of pizzas and and burgers five in number and 1 salad\n",
      "token lemma pizza\n",
      "Token: pizzas\n",
      "Left children: []\n",
      "Right children: []\n",
      "\n",
      "token lemma burger\n",
      "Token: burgers\n",
      "Left children: []\n",
      "Right children: ['five']\n",
      "\n",
      "token lemma salad\n",
      "Token: salad\n",
      "Left children: ['number']\n",
      "Right children: []\n",
      "\n",
      "order is  {'pizza': 1, 'burger': 5, 'salad': 1}\n",
      "Order processed and saved to order_customer_001.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to convert audio to text\n",
    "def audio_to_text(file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio.export(\"temp.wav\", format=\"wav\")\n",
    "    \n",
    "    with sr.AudioFile(\"temp.wav\") as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio_data = recognizer.listen(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Could not understand the audio\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Could not request results from Google Web Speech API; {e}\"\n",
    "\n",
    "#  Caterer food item dataset\n",
    "food_items = [\"pizza\", \"burger\", \"pasta\", \"salad\", \"soda\", \"sandwich\",\"sadhya\", \"payasam\"]\n",
    "\n",
    "# Function to extract food items and quantities from text using spaCy\n",
    "def extract_food_items(text, food_items):\n",
    "    #To correct some common transcription error occured\n",
    "    text=\"i want two number of pizzas and and burgers five in number and 1 salad\"\n",
    "    text = correct_transcription_items(text) \n",
    "    text = correct_transcription_quantity(text)\n",
    "    print('corrected text',text)\n",
    "    doc = nlp(text.lower()) #several nlp process are performed. a pipeline of events including tokenisation, lemmatization .....\n",
    "    order = {}\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.lemma_ in food_items:\n",
    "            print('token lemma',token.lemma_)\n",
    "            # Find the quantity by checking the token's left children for numbers\n",
    "            quantity = 1  # Default quantity\n",
    "            print(f\"Token: {token.text}\")\n",
    "            print(\"Left children:\", [child.text for child in token.lefts])\n",
    "            print(\"Right children:\", [child.text for child in token.rights])\n",
    "            print()\n",
    "            for child in token.lefts:\n",
    "                if child.like_num:\n",
    "                    quantity = int(w2n.word_to_num(child.text))  #get the numerical value and store to the quantity\n",
    "                    break\n",
    "            for child in token.rights:\n",
    "                if child.like_num:\n",
    "                    quantity = int(w2n.word_to_num(child.text))\n",
    "                    break\n",
    "            if token.lemma_ in order:    #if the perticular token is already in the dictionary the quantity is updated\n",
    "                order[token.lemma_] += quantity\n",
    "            else:\n",
    "                order[token.lemma_] = quantity\n",
    "    \n",
    "    return order\n",
    "\n",
    "# Function to structure extracted data into a DataFrame\n",
    "def structure_data(order, customer_id):\n",
    "    df = pd.DataFrame(list(order.items()), columns=[\"Food Item\", \"Quantity\"])\n",
    "    df[\"Customer ID\"] = customer_id\n",
    "    return df\n",
    "#function to correct some common transciption error of items\n",
    "def correct_transcription_items(text):\n",
    "    corrections = {\n",
    "        r'\\bbrothers\\b': 'burgers',\n",
    "        r'\\bsadiya\\b': 'sadhya',\n",
    "        r'\\bsathya\\b': 'sadhya',\n",
    "        \n",
    "        \n",
    "        # Add more specific corrections as needed\n",
    "    }\n",
    "    for pattern, replacement in corrections.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "    \n",
    "#function to correct some common transcription error of the quantity\n",
    "\n",
    "def correct_transcription_quantity(text):\n",
    "    corrections = {\n",
    "        r'\\bto burgers\\b': 'two burgers',\n",
    "        r'\\bto pizza\\b': 'two pizza',\n",
    "        r'\\bto sadhya\\b': 'two sadhya',\n",
    "        r'\\bto payasam\\b': 'two payasam',\n",
    "        r'\\bon pizzas\\b': 'one pizza',\n",
    "        r'\\bon burger\\b': 'one burger',\n",
    "        r'\\bon sadhya\\b': 'one sadhya',\n",
    "        r'\\bon payasam\\b': 'one payasam',\n",
    "        # Add more specific corrections as needed\n",
    "    }\n",
    "    \n",
    "    for pattern, replacement in corrections.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "    \n",
    "# Function to process the order\n",
    "def process_order(file_path, customer_id):\n",
    "    #  Convert audio to text using google speach recognition api \n",
    "    text = audio_to_text(file_path)\n",
    "    print('audio text is', text)\n",
    "    if \"Could not\" in text:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    #  Extract food items and quantities\n",
    "    order = extract_food_items(text, food_items)\n",
    "    print('order is ',order)\n",
    "    \n",
    "    # Step 3: Structure data\n",
    "    if order:\n",
    "        df = structure_data(order, customer_id)\n",
    "        output_file = f\"order_{customer_id}.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Order processed and saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid food items found in the order\")\n",
    "\n",
    "# audio to csv file of a recording \n",
    "process_order(\"Recording9.wav\", \"customer_001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d391669-9a42-4e27-9ae7-b165193e3f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
